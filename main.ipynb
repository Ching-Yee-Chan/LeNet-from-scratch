{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习导论作业三：LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# do some setup\n",
    "from data import get_mnist_data\n",
    "from model import LeNet5\n",
    "from train import Solver\n",
    "import pickle\n",
    "\n",
    "%matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data from files...\n",
      "Load images from mnist_data/train-images.idx3-ubyte, number: 60000, data shape: (60000, 28, 28)\n",
      "Load images from mnist_data/train-labels.idx1-ubyte, number: 60000, data shape: (60000,)\n",
      "Load images from mnist_data/t10k-images.idx3-ubyte, number: 10000, data shape: (10000, 28, 28)\n",
      "Load images from mnist_data/t10k-labels.idx1-ubyte, number: 10000, data shape: (10000,)\n",
      "X_train: (59000, 1, 32, 32)\n",
      "y_train: (59000,)\n",
      "X_val: (1000, 1, 32, 32)\n",
      "y_val: (1000,)\n",
      "X_test: (10000, 1, 32, 32)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) MNIST data.\n",
    "data = get_mnist_data(num_validation=1000, subtract_mean=True)\n",
    "for k, v in list(data.items()):\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 50 / 295) loss: 2.082834\n",
      "(Iteration 100 / 295) loss: 1.171335\n",
      "(Iteration 150 / 295) loss: 0.673421\n",
      "(Iteration 200 / 295) loss: 0.387437\n",
      "(Iteration 250 / 295) loss: 0.272811\n",
      "(Epoch 1 / 40) train acc: 0.948475; val_acc: 0.957000\n",
      "(Iteration 50 / 295) loss: 0.084396\n",
      "(Iteration 100 / 295) loss: 0.132997\n",
      "(Iteration 150 / 295) loss: 0.107211\n",
      "(Iteration 200 / 295) loss: 0.104909\n",
      "(Iteration 250 / 295) loss: 0.215001\n",
      "(Epoch 2 / 40) train acc: 0.976203; val_acc: 0.983000\n",
      "(Iteration 50 / 295) loss: 0.030956\n",
      "(Iteration 100 / 295) loss: 0.089779\n",
      "(Iteration 150 / 295) loss: 0.092252\n",
      "(Iteration 200 / 295) loss: 0.065919\n",
      "(Iteration 250 / 295) loss: 0.180790\n",
      "(Epoch 3 / 40) train acc: 0.981186; val_acc: 0.982000\n",
      "(Iteration 50 / 295) loss: 0.027677\n",
      "(Iteration 100 / 295) loss: 0.055839\n",
      "(Iteration 150 / 295) loss: 0.068286\n",
      "(Iteration 200 / 295) loss: 0.058679\n",
      "(Iteration 250 / 295) loss: 0.132767\n",
      "(Epoch 4 / 40) train acc: 0.983305; val_acc: 0.987000\n",
      "(Iteration 50 / 295) loss: 0.026135\n",
      "(Iteration 100 / 295) loss: 0.057128\n",
      "(Iteration 150 / 295) loss: 0.062420\n",
      "(Iteration 200 / 295) loss: 0.061000\n",
      "(Iteration 250 / 295) loss: 0.110462\n",
      "(Epoch 5 / 40) train acc: 0.985136; val_acc: 0.988000\n",
      "(Iteration 50 / 295) loss: 0.022844\n",
      "(Iteration 100 / 295) loss: 0.064603\n",
      "(Iteration 150 / 295) loss: 0.056703\n",
      "(Iteration 200 / 295) loss: 0.050116\n",
      "(Iteration 250 / 295) loss: 0.088677\n",
      "(Epoch 6 / 40) train acc: 0.986695; val_acc: 0.986000\n",
      "(Iteration 50 / 295) loss: 0.024818\n",
      "(Iteration 100 / 295) loss: 0.065128\n",
      "(Iteration 150 / 295) loss: 0.049536\n",
      "(Iteration 200 / 295) loss: 0.050335\n",
      "(Iteration 250 / 295) loss: 0.073030\n",
      "(Epoch 7 / 40) train acc: 0.984746; val_acc: 0.987000\n",
      "(Iteration 50 / 295) loss: 0.030740\n",
      "(Iteration 100 / 295) loss: 0.051472\n",
      "(Iteration 150 / 295) loss: 0.060149\n",
      "(Iteration 200 / 295) loss: 0.037474\n",
      "(Iteration 250 / 295) loss: 0.070617\n",
      "(Epoch 8 / 40) train acc: 0.985542; val_acc: 0.989000\n",
      "(Iteration 50 / 295) loss: 0.025243\n",
      "(Iteration 100 / 295) loss: 0.042153\n",
      "(Iteration 150 / 295) loss: 0.062290\n",
      "(Iteration 200 / 295) loss: 0.046285\n",
      "(Iteration 250 / 295) loss: 0.061094\n",
      "(Epoch 9 / 40) train acc: 0.987390; val_acc: 0.989000\n",
      "(Iteration 50 / 295) loss: 0.031627\n",
      "(Iteration 100 / 295) loss: 0.038714\n",
      "(Iteration 150 / 295) loss: 0.073528\n",
      "(Iteration 200 / 295) loss: 0.039189\n",
      "(Iteration 250 / 295) loss: 0.062656\n",
      "(Epoch 10 / 40) train acc: 0.990797; val_acc: 0.989000\n",
      "Saving checkpoint to \"3_epoch_10.pkl\"\n",
      "(Iteration 50 / 295) loss: 0.025887\n",
      "(Iteration 100 / 295) loss: 0.043753\n",
      "(Iteration 150 / 295) loss: 0.047950\n",
      "(Iteration 200 / 295) loss: 0.034328\n",
      "(Iteration 250 / 295) loss: 0.059810\n",
      "(Epoch 11 / 40) train acc: 0.988407; val_acc: 0.989000\n",
      "(Iteration 50 / 295) loss: 0.028586\n",
      "(Iteration 100 / 295) loss: 0.035192\n",
      "(Iteration 150 / 295) loss: 0.041159\n",
      "(Iteration 200 / 295) loss: 0.042712\n",
      "(Iteration 250 / 295) loss: 0.087560\n",
      "(Epoch 12 / 40) train acc: 0.983780; val_acc: 0.977000\n",
      "(Iteration 50 / 295) loss: 0.024767\n",
      "(Iteration 100 / 295) loss: 0.041744\n",
      "(Iteration 150 / 295) loss: 0.032464\n",
      "(Iteration 200 / 295) loss: 0.026558\n",
      "(Iteration 250 / 295) loss: 0.052577\n",
      "(Epoch 13 / 40) train acc: 0.994102; val_acc: 0.990000\n",
      "(Iteration 50 / 295) loss: 0.024623\n",
      "(Iteration 100 / 295) loss: 0.038984\n",
      "(Iteration 150 / 295) loss: 0.034080\n",
      "(Iteration 200 / 295) loss: 0.031826\n",
      "(Iteration 250 / 295) loss: 0.028276\n",
      "(Epoch 14 / 40) train acc: 0.994119; val_acc: 0.990000\n",
      "(Iteration 50 / 295) loss: 0.025695\n",
      "(Iteration 100 / 295) loss: 0.024176\n",
      "(Iteration 150 / 295) loss: 0.032455\n",
      "(Iteration 200 / 295) loss: 0.023728\n",
      "(Iteration 250 / 295) loss: 0.035273\n",
      "(Epoch 15 / 40) train acc: 0.996475; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.024771\n",
      "(Iteration 100 / 295) loss: 0.026109\n",
      "(Iteration 150 / 295) loss: 0.044412\n",
      "(Iteration 200 / 295) loss: 0.025894\n",
      "(Iteration 250 / 295) loss: 0.044492\n",
      "(Epoch 16 / 40) train acc: 0.997153; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.023875\n",
      "(Iteration 100 / 295) loss: 0.022416\n",
      "(Iteration 150 / 295) loss: 0.041667\n",
      "(Iteration 200 / 295) loss: 0.021602\n",
      "(Iteration 250 / 295) loss: 0.033235\n",
      "(Epoch 17 / 40) train acc: 0.997915; val_acc: 0.990000\n",
      "(Iteration 50 / 295) loss: 0.020240\n",
      "(Iteration 100 / 295) loss: 0.020176\n",
      "(Iteration 150 / 295) loss: 0.028569\n",
      "(Iteration 200 / 295) loss: 0.020030\n",
      "(Iteration 250 / 295) loss: 0.025416\n",
      "(Epoch 18 / 40) train acc: 0.998831; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.019085\n",
      "(Iteration 100 / 295) loss: 0.019630\n",
      "(Iteration 150 / 295) loss: 0.022592\n",
      "(Iteration 200 / 295) loss: 0.019497\n",
      "(Iteration 250 / 295) loss: 0.022989\n",
      "(Epoch 19 / 40) train acc: 0.999373; val_acc: 0.990000\n",
      "(Iteration 50 / 295) loss: 0.018449\n",
      "(Iteration 100 / 295) loss: 0.018890\n",
      "(Iteration 150 / 295) loss: 0.020743\n",
      "(Iteration 200 / 295) loss: 0.018560\n",
      "(Iteration 250 / 295) loss: 0.020589\n",
      "(Epoch 20 / 40) train acc: 0.999627; val_acc: 0.990000\n",
      "Saving checkpoint to \"3_epoch_20.pkl\"\n",
      "(Iteration 50 / 295) loss: 0.017871\n",
      "(Iteration 100 / 295) loss: 0.018328\n",
      "(Iteration 150 / 295) loss: 0.019411\n",
      "(Iteration 200 / 295) loss: 0.018104\n",
      "(Iteration 250 / 295) loss: 0.020248\n",
      "(Epoch 21 / 40) train acc: 0.999695; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.017381\n",
      "(Iteration 100 / 295) loss: 0.017859\n",
      "(Iteration 150 / 295) loss: 0.018697\n",
      "(Iteration 200 / 295) loss: 0.017607\n",
      "(Iteration 250 / 295) loss: 0.018980\n",
      "(Epoch 22 / 40) train acc: 0.999695; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.016966\n",
      "(Iteration 100 / 295) loss: 0.017493\n",
      "(Iteration 150 / 295) loss: 0.018082\n",
      "(Iteration 200 / 295) loss: 0.017131\n",
      "(Iteration 250 / 295) loss: 0.018250\n",
      "(Epoch 23 / 40) train acc: 0.999746; val_acc: 0.992000\n",
      "(Iteration 50 / 295) loss: 0.016616\n",
      "(Iteration 100 / 295) loss: 0.017141\n",
      "(Iteration 150 / 295) loss: 0.017660\n",
      "(Iteration 200 / 295) loss: 0.016750\n",
      "(Iteration 250 / 295) loss: 0.017568\n",
      "(Epoch 24 / 40) train acc: 0.999814; val_acc: 0.992000\n",
      "(Iteration 50 / 295) loss: 0.016319\n",
      "(Iteration 100 / 295) loss: 0.016922\n",
      "(Iteration 150 / 295) loss: 0.017207\n",
      "(Iteration 200 / 295) loss: 0.016452\n",
      "(Iteration 250 / 295) loss: 0.017213\n",
      "(Epoch 25 / 40) train acc: 0.999864; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.016072\n",
      "(Iteration 100 / 295) loss: 0.016654\n",
      "(Iteration 150 / 295) loss: 0.016896\n",
      "(Iteration 200 / 295) loss: 0.016217\n",
      "(Iteration 250 / 295) loss: 0.016882\n",
      "(Epoch 26 / 40) train acc: 0.999864; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015856\n",
      "(Iteration 100 / 295) loss: 0.016465\n",
      "(Iteration 150 / 295) loss: 0.016633\n",
      "(Iteration 200 / 295) loss: 0.016015\n",
      "(Iteration 250 / 295) loss: 0.016681\n",
      "(Epoch 27 / 40) train acc: 0.999881; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015675\n",
      "(Iteration 100 / 295) loss: 0.016278\n",
      "(Iteration 150 / 295) loss: 0.016429\n",
      "(Iteration 200 / 295) loss: 0.015841\n",
      "(Iteration 250 / 295) loss: 0.016454\n",
      "(Epoch 28 / 40) train acc: 0.999881; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015519\n",
      "(Iteration 100 / 295) loss: 0.016128\n",
      "(Iteration 150 / 295) loss: 0.016249\n",
      "(Iteration 200 / 295) loss: 0.015702\n",
      "(Iteration 250 / 295) loss: 0.016377\n",
      "(Epoch 29 / 40) train acc: 0.999915; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015391\n",
      "(Iteration 100 / 295) loss: 0.016013\n",
      "(Iteration 150 / 295) loss: 0.016097\n",
      "(Iteration 200 / 295) loss: 0.015578\n",
      "(Iteration 250 / 295) loss: 0.016291\n",
      "(Epoch 30 / 40) train acc: 0.999915; val_acc: 0.991000\n",
      "Saving checkpoint to \"3_epoch_30.pkl\"\n",
      "(Iteration 50 / 295) loss: 0.015280\n",
      "(Iteration 100 / 295) loss: 0.015895\n",
      "(Iteration 150 / 295) loss: 0.015992\n",
      "(Iteration 200 / 295) loss: 0.015476\n",
      "(Iteration 250 / 295) loss: 0.016202\n",
      "(Epoch 31 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015187\n",
      "(Iteration 100 / 295) loss: 0.015826\n",
      "(Iteration 150 / 295) loss: 0.015893\n",
      "(Iteration 200 / 295) loss: 0.015382\n",
      "(Iteration 250 / 295) loss: 0.016156\n",
      "(Epoch 32 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015109\n",
      "(Iteration 100 / 295) loss: 0.015750\n",
      "(Iteration 150 / 295) loss: 0.015831\n",
      "(Iteration 200 / 295) loss: 0.015307\n",
      "(Iteration 250 / 295) loss: 0.016106\n",
      "(Epoch 33 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.015046\n",
      "(Iteration 100 / 295) loss: 0.015683\n",
      "(Iteration 150 / 295) loss: 0.015764\n",
      "(Iteration 200 / 295) loss: 0.015241\n",
      "(Iteration 250 / 295) loss: 0.016040\n",
      "(Epoch 34 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014993\n",
      "(Iteration 100 / 295) loss: 0.015625\n",
      "(Iteration 150 / 295) loss: 0.015721\n",
      "(Iteration 200 / 295) loss: 0.015190\n",
      "(Iteration 250 / 295) loss: 0.015996\n",
      "(Epoch 35 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014950\n",
      "(Iteration 100 / 295) loss: 0.015581\n",
      "(Iteration 150 / 295) loss: 0.015681\n",
      "(Iteration 200 / 295) loss: 0.015146\n",
      "(Iteration 250 / 295) loss: 0.015928\n",
      "(Epoch 36 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014915\n",
      "(Iteration 100 / 295) loss: 0.015542\n",
      "(Iteration 150 / 295) loss: 0.015650\n",
      "(Iteration 200 / 295) loss: 0.015111\n",
      "(Iteration 250 / 295) loss: 0.015882\n",
      "(Epoch 37 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014886\n",
      "(Iteration 100 / 295) loss: 0.015509\n",
      "(Iteration 150 / 295) loss: 0.015618\n",
      "(Iteration 200 / 295) loss: 0.015086\n",
      "(Iteration 250 / 295) loss: 0.015840\n",
      "(Epoch 38 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014863\n",
      "(Iteration 100 / 295) loss: 0.015484\n",
      "(Iteration 150 / 295) loss: 0.015595\n",
      "(Iteration 200 / 295) loss: 0.015063\n",
      "(Iteration 250 / 295) loss: 0.015802\n",
      "(Epoch 39 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "(Iteration 50 / 295) loss: 0.014844\n",
      "(Iteration 100 / 295) loss: 0.015464\n",
      "(Iteration 150 / 295) loss: 0.015574\n",
      "(Iteration 200 / 295) loss: 0.015046\n",
      "(Iteration 250 / 295) loss: 0.015775\n",
      "(Epoch 40 / 40) train acc: 0.999932; val_acc: 0.991000\n",
      "Saving checkpoint to \"3_epoch_40.pkl\"\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5(weight_scale=0.001, reg=0.001)\n",
    "\n",
    "solver = Solver(\n",
    "    model,\n",
    "    data,\n",
    "    num_epochs=40,\n",
    "    optimizer='adam',\n",
    "    optim_config={'learning_rate': 1e-3,},\n",
    "    lr_decay = 0.8, \n",
    "    batch_size=200,\n",
    "    print_every = 50, \n",
    "    exp_num = 3,\n",
    ")\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Print test set accuracy.\n",
    "print(\n",
    "    \"Test accuracy:\",\n",
    "    solver.check_accuracy(data['X_test'], data['y_test'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint \"2_epoch_30.pkl\"\n"
     ]
    }
   ],
   "source": [
    "#load from checkpoint\n",
    "filename = \"2_epoch_30.pkl\"\n",
    "print('Loading checkpoint \"%s\"' % filename)\n",
    "with open(filename, \"rb\") as f:\n",
    "    solver.model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "plt.figure(dpi=100, figsize=(20, 6))\n",
    "plt.plot(solver.loss_history, 'o', markersize = 2)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100, figsize=(20, 6))\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(\"accu.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, classes=[]):\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "    plt.figure(1, figsize=(16, 8))\n",
    "    sns.set(font_scale=1.5, color_codes=True, palette='deep')\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={'size': 16}, fmt='d', cmap='YlGnBu')\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "y_pred = solver.check_accuracy(data['X_test'], None, get_label=True)\n",
    "plot_confusion_matrix(data['y_test'], y_pred, list(range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d437476005cff51462e9417396f7c31ae9ae2568db0a2117c71fbac8b9386c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
